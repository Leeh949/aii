{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cec3b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.text_cell_render.rendered_html{font-size:12pt;}\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;};\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.text_cell_render.rendered_html{font-size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;};\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8068a179",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch2. ollama_LLM활용의 기본 개념 (Langchain)</span>\n",
    "# 1. LLM을 활용하여 답변 생성하기\n",
    "## 1) Ollama를 이용한 로컬 LLM이용\n",
    "성능은 GPT, CLaude 같은 모델보다 떨어지나, 개념설명을 위해 open source 모델 사용\n",
    "\n",
    "### ollama.com다운로드  설치 모델 pull\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa7c9a",
   "metadata": {},
   "source": [
    "### 모델 pull\n",
    "- cmd창이나 powershell창 window키 r power shell에서 ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5aa494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of South Korea is Seoul.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-10T01:15:22.0074599Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3039381300, 'load_duration': 2422017600, 'prompt_eval_count': 33, 'prompt_eval_duration': 301840100, 'eval_count': 9, 'eval_duration': 305299500, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b05d3-b430-7d73-b767-4881e2fd2763-0', usage_metadata={'input_tokens': 33, 'output_tokens': 9, 'total_tokens': 42})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm= ChatOllama(model=\"llama3.2:1b\")\n",
    "result= llm.invoke(\"What is the capital of korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce4e804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Korea is Seoul.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "742414e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result= llm.invoke(\"한국 수도가 어디예요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf47f934",
   "metadata": {},
   "source": [
    "## 2) openai 활용\n",
    "- pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5da7c1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 환경변수 가져오기\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "# load_dotenv()\n",
    "# # os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f155ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# llm= ChatOpenAI(model=\"gpt-5-nano\",\n",
    "# #                 api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "#                )\n",
    "# result= llm.invoke(\"What is the capital of Korea? Return the name of the city only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4e3d7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Seoul', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 395, 'prompt_tokens': 20, 'total_tokens': 415, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CkkXeFTlusludFa1l3Vnn4nM2vr6z', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b0193-e100-7410-951d-3cf424e75f51-0', usage_metadata={'input_tokens': 20, 'output_tokens': 395, 'total_tokens': 415, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16ec3563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # claud모델\n",
    "# from langchain_openai import AzureOpenAI\n",
    "# llm= AzureOpenAI(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6993915b",
   "metadata": {},
   "source": [
    "# 2. 렝체인 스타일로 프롬프트 작성\n",
    "- 프롬프트: llm호출시 쓰는 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c43afc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It seems like you started to ask a question or pose a query, but it got cut off. Could you please complete your thought or ask a question? I'm here to help.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T05:38:04.5719875Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3066100900, 'load_duration': 1339582900, 'prompt_eval_count': 26, 'prompt_eval_duration': 267011700, 'eval_count': 38, 'eval_duration': 1415560200, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b019d-dca0-7dc0-af47-53b13b89e93e-0', usage_metadata={'input_tokens': 26, 'output_tokens': 38, 'total_tokens': 64})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm= ChatOllama(model=\"llama3.2:1b\")\n",
    "# llm.invoke(0)\n",
    "# PromptValue, str, BaseMessages리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442b67a6",
   "metadata": {},
   "source": [
    "## 1) 기본 프롬프트 템플릿 사용\n",
    "- PromptTemplate 을 사용하여 변수가 포함된 템플릿을 작성하면 PromptValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d03c34b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='What is the capital of Korea?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of South Korea is Seoul. However, it's worth noting that North Korea also claims Seoul as its capital, which is often referred to as Pyongyang in North Korean government documents and official websites. This dual claim is due to a complex history between the two countries, with Seoul being occupied by United States forces from 1910 to 1945 and then becoming part of Japan during World War II, before eventually becoming the de facto capital of South Korea after the end of the war.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T05:48:04.7032035Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5370123800, 'load_duration': 1340859600, 'prompt_eval_count': 32, 'prompt_eval_duration': 240582800, 'eval_count': 99, 'eval_duration': 3690896200, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01a6-fbe1-7d92-a3a8-73c9e644bd81-0', usage_metadata={'input_tokens': 32, 'output_tokens': 99, 'total_tokens': 131})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "llm= ChatOllama(model=\"llama3.2:1b\")\n",
    "prompt_template= PromptTemplate(\n",
    "    template=\"What is the capital of {country}?\", #{}안의 값을 새로운 값으로 대입 가능\n",
    "    input_variables= [\"country\"]\n",
    ")\n",
    "\n",
    "# country= input('어느 나라의 수도를 알고싶으신가요?')\n",
    "prompt= prompt_template.invoke({\"country\":\"Korea\"})\n",
    "print(prompt)\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38984fb4",
   "metadata": {},
   "source": [
    "## 2) 메세지 기반 프롬프트 작성\n",
    "- BaseMessage 리스트\n",
    "- BaseMessage 상속받은 클래스: AIMessage, HumanMessage, SystemMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae157b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of South Korea is Seoul.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "message_list=[\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"), # 페르소나 부여\n",
    "    \n",
    "    HumanMessage(content=\" What is the capital of Italy?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"), #모법답안\n",
    "    HumanMessage(content=\"What is the capital of France?\"), #모범 답안\n",
    "    AIMessage(content=\"The capital of France is Paris.\"),\n",
    "    HumanMessage(content=\"What is the capital of South Korea?\")\n",
    "]\n",
    "result= llm.invoke(message_list)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "400bb200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"If you don't mention a specific country, I can suggest some examples:\\n\\n- United States: Washington D.C.\\n- China: Beijing\\n- Japan: Tokyo\\n- Australia: Canberra\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:22:45.5852913Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3433689600, 'load_duration': 1343844300, 'prompt_eval_count': 85, 'prompt_eval_duration': 631326700, 'eval_count': 38, 'eval_duration': 1412869800, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01c6-c3e5-7e51-a7e3-e634abd6c262-0', usage_metadata={'input_tokens': 85, 'output_tokens': 38, 'total_tokens': 123})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "message_list=[\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"), # 페르소나 부여\n",
    "    HumanMessage(content=\" What is the capital of Italy?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of Italy is Rome\"), #모법답안\n",
    "    HumanMessage(content=\"What is the capital of France?\"), #모범 질문\n",
    "    AIMessage(content=\"The capital of France is Paris\"), #모범 답안\n",
    "    HumanMessage(content=\"What is the capital of {country}?\")\n",
    "]\n",
    "llm.invoke(message_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc47909",
   "metadata": {},
   "source": [
    "## 3) ChatPromptTemplate 사용\n",
    "- BaseMessage리스트 -> 튜플리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51c57b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요?USA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of the United States of America is Washington, D.C. (short for District of Columbia).'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 BaseMessage 리스트를 수정\n",
    "# PromptTemplate: 프롬프트에 변수포함,\n",
    "# ChatPromptTemplate: SystemPrompt설정(페르소나), few shot설정, 변수포함\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "chatPrompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpfull assistant\"),\n",
    "    (\"human\",\"What is the capital of Italy?\"),\n",
    "    (\"ai\",\"The capital of Italy is Rome.\"),\n",
    "    (\"human\",\"What is the capital of France?\"),\n",
    "    (\"ai\",\"The capital of France is Paris\"),\n",
    "    ('human',\"What is the capital of {country}?\")\n",
    "])\n",
    "country= input(\"어느 나라 수도가 궁금하세요?\")\n",
    "prompt= chatPrompt_template.invoke({\"country\":country})\n",
    "# print(\"프롬프트:\", prompt,type(prompt))\n",
    "result= llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "568e9d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요Korea\n",
      "한국의 수도는 Seoul입니다. Seoul은 한국에서 가장 큰 도시이자 국가의 수도이며, 한국 역사와文化의 주요 цент Corey로 유명합니다.\n"
     ]
    }
   ],
   "source": [
    "chatPromptTemplate= ChatPromptTemplate.from_messages([\n",
    "    ('system',\"당신은 대한민국 정보 전문 도우미입니다\"),\n",
    "    (\"human\", \"{country}의 수도는 어디예요!\")\n",
    "])\n",
    "country= input(\"어느 나라 수도가 궁금하세요\")\n",
    "prompt= chatPromptTemplate.invoke({\"country\":country})\n",
    "result= llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c019abcf",
   "metadata": {},
   "source": [
    "# 3. 답변 형식 컨트롤 하기\n",
    "- llm.invoke()의 결과는 AIMessage() -> string이나 json, 객체: OutputParser이용\n",
    "\n",
    "## 1) 문자열 출력 파서 이용\n",
    "- strOutputParser를 사용하여 LLM출력(AIMessage)을 단순 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c05008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 명시적인 지시하상이 포함된 프롬프트\n",
    "prompt_template= PromptTemplate(\n",
    "    template= \"What is the capital of {country}. Return the name of the city only\",\n",
    "    input_variables= ['country']\n",
    ")\n",
    "# 프롬프트 템플릿에 값 주입\n",
    "prompt= prompt_template.invoke({\"country\":\"Korea\"})\n",
    "# print(prompt)\n",
    "ai_message= llm.invoke(prompt)\n",
    "# print(ai_message)\n",
    "# 문자열 출력 파서를 이용하여 llm응답(AIMessage객체)을 단순 문자열로 변환\n",
    "output_parser= StrOutputParser()\n",
    "result= output_parser.invoke(ai_message)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f78ba6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d64e238b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수설정, system, few shot 지정\n",
    "chat_prompt_template= ChatPromptTemplate([\n",
    "    (\"system\",\"You are a helpful assistant with expertise in South Korea\"),\n",
    "    (\"human\",\"What is the capital of Italy?\"),\n",
    "    (\"ai\",\"Rome.\"),\n",
    "    (\"human\",\"What is the capital of France?\"),\n",
    "    (\"ai\",\"Paris\"),\n",
    "    (\"human\",\"What is the capital of {country}Return the name of the city only\")\n",
    "])\n",
    "output_parser= StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(chat_prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b978d72",
   "metadata": {},
   "source": [
    "## 2) Json출력파서 이용\n",
    "- {'name','홍길동', 'age',22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99853162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'capital': 'Seoul', 'population': 51.8, 'language': 'Korean', 'currency': 'KRW'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "country_detail_prompt= PromptTemplate(\n",
    "    template=\"\"\" Give following information about {country}.\n",
    "    -capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "prompt= country_detail_prompt.invoke({\"country\":\"Korea\"})\n",
    "ai_message= llm.invoke(prompt)\n",
    "# print(ai_message.content)\n",
    "output_parser = JsonOutputParser()\n",
    "json_result= output_parser.invoke(ai_message)\n",
    "print(json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a1018f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Tokyo',\n",
       " 'population': 1282340000,\n",
       " 'language': 'Japanese',\n",
       " 'currency': 'Yen'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(country_detail_prompt.invoke({'country':'Japan'})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29742c09",
   "metadata": {},
   "source": [
    "## 3) 구조화 된 출력 사용\n",
    "- Pydantic 모델을 사용하여 LLM출력을 구조화 된 형식으로 받기(JsonParser보다 훨씬 안정적)\n",
    "- Pydantic: 데이터 유효성검사, 설정관리를 간편하게 해주는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4739a457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.User object at 0x00000197C3C10D30>\n"
     ]
    }
   ],
   "source": [
    "class User:\n",
    "    def __init__(self, id, name, is_active=True):\n",
    "        self.id= id\n",
    "        self.name=name\n",
    "        self.is_active= is_active\n",
    "user= User(\"1\", \"홍길동\",False)\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fc76900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='홍길동' is_active=True\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "#     gt=0:id>0 / ge=0:id>=0 / lt=0 :id<0 / le=0:id<=0\n",
    "    id:int=Field(gt=0, description=\"id\")\n",
    "    name:str= Field(min_length=2, description=\"name\")\n",
    "    is_active:bool=Field(default=True, description=\"id활성화 여부\")\n",
    "user= User(id=1, name=\"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47e045af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountryDetail(capital='Seoul', population=51, language='Korean', currency='KRW')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt= PromptTemplate(\n",
    "    template=\"\"\" Give following information about {country}.\n",
    "    -capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "class CountryDetail(BaseModel): #description: 더 정확한 출력 유도\n",
    "    capital:str= Field(description=\"the Capital of the country\")\n",
    "    population:int=Field(description=\"the population of the country\")\n",
    "    language:str=Field(description=\"the language of the country\")\n",
    "    currency:str=Field(description=\"the currency of the country\")\n",
    "# 출력 혈식 파서 + LLM\n",
    "structedllm= llm.with_structured_output(CountryDetail)\n",
    "# llm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "# structedllm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "info = structedllm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2716fe87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Seoul', 51, 'Korean', 'KRW')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.capital, info.population, info.language, info.currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3034052e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info를 json으로: {\"capital\":\"Seoul\",\"population\":51,\"language\":\"Korean\",\"currency\":\"KRW\"}\n",
      "info를 dict로 : {'capital': 'Seoul', 'population': 51, 'language': 'Korean', 'currency': 'KRW'}\n",
      "info를 dict로 : {'capital': 'Seoul', 'population': 51, 'language': 'Korean', 'currency': 'KRW'}\n"
     ]
    }
   ],
   "source": [
    "print(\"info를 json으로:\", info.model_dump_json()) # 문자열\n",
    "print(\"info를 dict로 :\", info.model_dump()) #dict 값 키:값\n",
    "print(\"info를 dict로 :\", info.__dict__) #dict 키: 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9e2a95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d61bc",
   "metadata": {},
   "source": [
    "# 4.LCEL을 활용한 렝체인 생성하기\n",
    "## 1) 문자열 출력 파서 사용\n",
    "- invoke: Runnable에 있는 함수\n",
    "- Stroutputparser, ChatOllama, PromptTemplate등은 모두 Runnable로부터 상속받음.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73706835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bibimbap'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm= ChatOllama(model=\"llama3.2:1b\",\n",
    "               temperature=0) #일관된 답변(보수적인 답변)\n",
    "prompt_template= PromptTemplate(\n",
    "    template= \"Please recommend the most famous food in the {country}. Return the name of the food only\",\n",
    "    input_variables= ['country']\n",
    ")\n",
    "output_parser= StrOutputParser() #AIMessage()를 Str 변환\n",
    "output_parser.invoke(llm.invoke(prompt_template.invoke({'country':'Korea'})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65555dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please recommend the most famous food in the {country}. Return the name of the food only'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Please recommend the most famous food in the {country}. Return the name of the food only\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea512b1b",
   "metadata": {},
   "source": [
    "## 2) LCEL을 사용한 간단한 체인 구성\n",
    "- 파이프연산자(|) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6d60c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Korea, there are many delicious foods to try, but one of the most famous and iconic dishes is likely \"Bibimbap.\" It\\'s a popular rice bowl dish topped with an assortment of vegetables, meat (usually beef), and a fried egg. The word \"Bibimbap\" literally means \"mixed rice,\" which refers to the combination of different ingredients.\\n\\nHowever, if you\\'re looking for something even more iconic, I\\'d recommend trying some \"Kimchi.\" Kimchi is a traditional Korean side dish made from fermented vegetables, usually cabbage or radish, seasoned with chili peppers, garlic, and other spices. It\\'s spicy, sour, and umami all at once, and it\\'s a staple in Korean cuisine.\\n\\nAnother famous Korean dish is \"Jeyuk Bokkeum,\" which is a stir-fried pork dish made with vegetables, such as zucchini, carrots, and onions, and sometimes mushrooms or tofu. The name \"Bokkeum\" literally means \"stir-fry,\" and this dish is a classic example of Korean cuisine.\\n\\nLastly, if you\\'re looking for something sweet, I\\'d recommend trying some \"Patbingsu.\" Patbingsu is a shaved ice dessert topped with sweet red bean, mochi, fruit, and condensed milk. It\\'s a popular summer treat in Korea, and it\\'s a great way to cool off on a hot day.\\n\\nThese are just a few examples of the many delicious foods you can try in Korea. Each region has its own specialties, so be sure to explore and find your favorite dishes!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> llm -> 출력파서를 연결하는 체인 생성\n",
    "capital_chain= prompt_template | llm | output_parser\n",
    "# 생성된 체인 invoke\n",
    "capital_chain.invoke({'country':'Korea'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5a5a2",
   "metadata": {},
   "source": [
    "## 3) 복합체인 구성\n",
    "- 여러단계의 추론이 필요한 경우(체인 연결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "409bac51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 -> 나라이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template=\"\"\" Guess the name of the country based on the following informat:\n",
    "    {information}\n",
    "    Return the name of the country only\"\"\",\n",
    "    input_variables=['information']\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "                                                       \"This country is very famous for its wine \"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "21b53043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라명 추출 체인 생성\n",
    "country_chain = country_prompt | llm | output_parser\n",
    "country_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c53a4af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 복합체인: 나라에 대한 설명-> 나라명(country_chain)\n",
    "#                           나라명 -> 수도 (capital_chain)\n",
    "final_chain= country_chain | capital_chain\n",
    "final_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d1b428f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복합체인: information -> country_chain -> (나라명을 country) -> capital_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "final_chain= {\"information\":RunnablePassthrough()} | \\\n",
    "                {\"country\":country_chain} | capital_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7c04a8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\"This country is very famous for its wine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc5bfe",
   "metadata": {},
   "source": [
    "- 한글 지원 여부 이 안되는 모델은 렝체인 연결이 잘 안 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e316db61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'위와 같이 나라이름을 맞춰 알려드리겠습니다.\\n\\n1. **오스트리아의 보이ern**: 오스트리아에서 만든 아크상트에이치 (Ahrtich) 와인.\\n2. **프랑스의 마르세유**: 프랑스에서 만든 마르세유 (Marsy) 와인.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 -> 나라이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template=\"\"\" 다음의{information} 설명을 보고 나라이름을 맞춰바:\n",
    "    {information}\n",
    "    나라이름만 한국어로 return해줘\"\"\",\n",
    "    input_variables=['information']\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "                                                       \"이 나라는 와인으로 유명해\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419ff2a2",
   "metadata": {},
   "source": [
    "# 5. 생성형 AI 평가: \n",
    "- 위: (나라설명 -> 나라이름 -> 수도)\n",
    "- 나라 이름 -> 그 나라에서 제일 유명한 음식 -> 음식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e6451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 복합체인 : 나라명 -> 그 나라에서 제일 유명한 음식(chain1)\n",
    "##                       나라명 -> 수도(capital_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22041597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "192.48px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
